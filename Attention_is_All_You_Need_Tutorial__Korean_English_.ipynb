{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cestclaire/programmers_project_results/blob/main/Attention_is_All_You_Need_Tutorial__Korean_English_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfTcLf-rjaWd"
      },
      "source": [
        "#### **Attention is All You Need (NIPS 2017)** 실습\n",
        "* <b>(뉴스 데이터셋)</b> 한국어 문장을 영어 문장으로 번역합니다.\n",
        "* 본 코드는 기본적으로 **Transformer** 논문의 내용을 최대한 따릅니다.\n",
        "    * 본 논문은 **딥러닝 기반의 자연어 처리** 기법의 기본적인 구성을 이해하고 공부하는 데에 도움을 줍니다.\n",
        "    * 2020년 기준 가장 뛰어난 번역 모델들은 본 논문에서 제안한 **Transformer 기반의 아키텍처**를 따르고 있습니다.\n",
        "* 코드 실행 전에 **[런타임]** → **[런타임 유형 변경]** → 유형을 **GPU**로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXXXOxNzeLpj"
      },
      "source": [
        "#### <b>한글 출력을 위한 폰트 설치</b>\n",
        "\n",
        "* 설치 이후에 수동으로 <b>[런타임]</b> - <b>[런타임 다시 시작]</b> 버튼을 눌러 재시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65nhszH6eNPt",
        "outputId": "2a68a0b0-7d49-4aca-a273-867aa8d5d06d"
      },
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 0s (21.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epJDFH3k03M6"
      },
      "source": [
        "#### <b>BLEU Score 계산을 위한 라이브러리 업데이트</b>\n",
        "\n",
        "* <b>[Restart Runtime]</b> 버튼을 눌러 런타임을 재시작할 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrr-S31b031u",
        "outputId": "c3831401-8c9c-478d-f09b-ad565d6d4e22"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OdH8Empjyxa"
      },
      "source": [
        "#### <b>한글 토큰화 라이브러리 설치하기</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2O0iSKl2mT_",
        "outputId": "33d45938-37ba-44b5-f202-93b96adf5da0"
      },
      "source": [
        "!pip3 install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 19.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5h73Lh9j2GW"
      },
      "source": [
        "#### <b>데이터셋 다운로드</b>\n",
        "\n",
        "* 한영 번역 데이터셋을 다운로드하여 파이썬 객체로 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdPZWIgl2oeF",
        "outputId": "c5f1d82d-fbfb-4583-edc8-ae913f6b955b"
      },
      "source": [
        "# 한영 번역 데이터셋을 포함하는 저장소\n",
        "!git clone https://github.com/ndb796/korean-parallel-corpora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'korean-parallel-corpora'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Total 131 (delta 0), reused 0 (delta 0), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (131/131), 17.67 MiB | 27.29 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2iBk4-k2qR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be4d033-80ae-4712-a3ad-0a06a3f75f57"
      },
      "source": [
        "# 데이터셋이 저장될 폴더 생성\n",
        "!mkdir -p ./dataset\n",
        "\n",
        "# 압축 해제\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.train.tar.gz -C ./dataset\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.test.tar.gz -C ./dataset\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.dev.tar.gz -C ./dataset\n",
        "\n",
        "# 학습(training) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.train.en ./dataset/train.en\n",
        "!mv ./dataset/korean-english-park.train.ko ./dataset/train.ko\n",
        "\n",
        "# 평가(validation) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.dev.en ./dataset/dev.en\n",
        "!mv ./dataset/korean-english-park.dev.ko ./dataset/dev.ko\n",
        "\n",
        "# 테스트(test) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.test.en ./dataset/test.en\n",
        "!mv ./dataset/korean-english-park.test.ko ./dataset/test.ko"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "korean-english-park.train.en\n",
            "korean-english-park.train.ko\n",
            "korean-english-park.test.en\n",
            "korean-english-park.test.ko\n",
            "korean-english-park.dev.en\n",
            "korean-english-park.dev.ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_JbLlFqOpAo"
      },
      "source": [
        "#### <b>데이터셋 읽어 확인하기</b>\n",
        "\n",
        "* 학습, 평가, 테스트 데이터셋을 각각 읽어 문장 데이터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcTMM_Em2rUJ"
      },
      "source": [
        "korean_lines_train = open(\"./dataset/train.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_train = open(\"./dataset/train.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "korean_lines_val = open(\"./dataset/dev.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_val = open(\"./dataset/dev.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "korean_lines_test = open(\"./dataset/test.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_test = open(\"./dataset/test.en\", 'r', encoding='utf-8').readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np7PF8SFkBNv",
        "outputId": "021ac168-62c7-4240-d15d-751662bb1d82"
      },
      "source": [
        "print(f\"한글 문장 학습 데이터 개수: {len(korean_lines_train)}개\")\n",
        "print(f\"영어 문장 학습 데이터 개수: {len(english_lines_train)}개\")\n",
        "\n",
        "print(f\"한글 문장 평가 데이터 개수: {len(korean_lines_val)}개\")\n",
        "print(f\"영어 문장 평가 데이터 개수: {len(english_lines_val)}개\")\n",
        "\n",
        "print(f\"한글 문장 테스트 데이터 개수: {len(korean_lines_test)}개\")\n",
        "print(f\"영어 문장 테스트 데이터 개수: {len(english_lines_test)}개\")\n",
        "\n",
        "index = 777\n",
        "print(f\"{index + 1}번째 학습용 한글 문장:\", korean_lines_train[index], end='')\n",
        "print(f\"{index + 1}번째 학습용 영어 문장:\", english_lines_train[index], end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한글 문장 학습 데이터 개수: 94123개\n",
            "영어 문장 학습 데이터 개수: 94123개\n",
            "한글 문장 평가 데이터 개수: 1000개\n",
            "영어 문장 평가 데이터 개수: 1000개\n",
            "한글 문장 테스트 데이터 개수: 2000개\n",
            "영어 문장 테스트 데이터 개수: 2000개\n",
            "778번째 학습용 한글 문장: 지금 21살인 유는 학교에 가기 전 서너시간 동안 컴퓨터 통신에 끼어들기 위해 새벽 5시에 침대에서 일어나 나온다.\n",
            "778번째 학습용 영어 문장: Now Yu, 21, drags herself out of bed at 5 a.m. to squeeze in a few hours online before school.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcLKB3BRkDKW"
      },
      "source": [
        "#### <b>단어 사전 만들기 </b>\n",
        "\n",
        "* 단어 사전 클래스를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWpaBry12tjd"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self):\n",
        "        self.UNK = '<unk>'\n",
        "        self.PAD = '<pad>'\n",
        "        self.SOS = '<sos>'\n",
        "        self.EOS = '<eos>'\n",
        "\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.word2count = {}\n",
        "\n",
        "    # 하나의 문장(sentence)에 포함된 모든 토큰을 추가하는 함수\n",
        "    def add_tokens(self, tokens):\n",
        "        for word in tokens:\n",
        "            if word in self.word2count:\n",
        "                self.word2count[word] += 1\n",
        "            else:\n",
        "                self.word2count[word] = 1\n",
        "\n",
        "    def preprocess(self, min_count):\n",
        "        # 사용하지 않을 단어 집합\n",
        "        trim_words = set()\n",
        "        for word, count in self.word2count.items():\n",
        "            if count < min_count:\n",
        "                trim_words.add(word)\n",
        "\n",
        "        # 실제로 사용할 단어만 남기기\n",
        "        words = set(self.word2count.keys()) - trim_words\n",
        "        words = [self.UNK, self.PAD, self.SOS, self.EOS] + list(words)\n",
        "\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        for i, word in enumerate(words):\n",
        "            self.word2idx[word] = i\n",
        "            self.idx2word[i] = word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSB5vFULkecQ"
      },
      "source": [
        "#### <b>문장 토큰화</b>\n",
        "\n",
        "* 먼저 한글 문장 및 영어 문장 데이터셋에 대하여 토큰화를 수행합니다.\n",
        "* 토큰화를 위해 특수문자 제거 함수를 정의하고 객체를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDH1f2gqlxO-"
      },
      "source": [
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "def clean_string(string):\n",
        "    string = string.strip() # 앞뒤로 존재하는 공백 제거\n",
        "    string = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', string) # 특수문자 제거\n",
        "    return string.strip().lower() # 소문자로 변환하여 반환\n",
        "\n",
        "okt = Okt() # 한글 형태소 분석기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fP80_AZmSC8"
      },
      "source": [
        "* 학습(training) 데이터셋을 토큰화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyKq4u8pmRlM",
        "outputId": "b6665911-5718-4167-9d7a-cf659f838bc9"
      },
      "source": [
        "tokenized_korean_lines_train = []\n",
        "tokenized_english_lines_train = []\n",
        "\n",
        "min_length = 4 # 단어의 개수가 4개 이상인 학습 문장 쌍만 사용\n",
        "max_length = 50 # 단어의 개수가 50개 이하인 학습 문장 쌍만 사용\n",
        "\n",
        "for i in range(len(korean_lines_train)):\n",
        "    korean = korean_lines_train[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_train[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    if len(korean_tokens) < min_length or len(korean_tokens) > max_length:\n",
        "        continue\n",
        "    if len(english_tokens) < min_length or len(english_tokens) > max_length:\n",
        "        continue\n",
        "\n",
        "    tokenized_korean_lines_train.append(korean_tokens)\n",
        "    tokenized_english_lines_train.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 4000 == 0:\n",
        "        print(f\"학습 데이터셋 토큰화: {i + 1}/{len(korean_lines_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋 토큰화: 4000/94123\n",
            "학습 데이터셋 토큰화: 8000/94123\n",
            "학습 데이터셋 토큰화: 12000/94123\n",
            "학습 데이터셋 토큰화: 16000/94123\n",
            "학습 데이터셋 토큰화: 20000/94123\n",
            "학습 데이터셋 토큰화: 24000/94123\n",
            "학습 데이터셋 토큰화: 28000/94123\n",
            "학습 데이터셋 토큰화: 32000/94123\n",
            "학습 데이터셋 토큰화: 36000/94123\n",
            "학습 데이터셋 토큰화: 40000/94123\n",
            "학습 데이터셋 토큰화: 44000/94123\n",
            "학습 데이터셋 토큰화: 48000/94123\n",
            "학습 데이터셋 토큰화: 52000/94123\n",
            "학습 데이터셋 토큰화: 56000/94123\n",
            "학습 데이터셋 토큰화: 60000/94123\n",
            "학습 데이터셋 토큰화: 64000/94123\n",
            "학습 데이터셋 토큰화: 68000/94123\n",
            "학습 데이터셋 토큰화: 72000/94123\n",
            "학습 데이터셋 토큰화: 76000/94123\n",
            "학습 데이터셋 토큰화: 80000/94123\n",
            "학습 데이터셋 토큰화: 84000/94123\n",
            "학습 데이터셋 토큰화: 88000/94123\n",
            "학습 데이터셋 토큰화: 92000/94123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DerYg_C1nOk7"
      },
      "source": [
        "* 평가(validation) 데이터셋을 토큰화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKrnkrbTnPoc",
        "outputId": "7249bbcb-1726-4308-8a76-ab73e9f1e06f"
      },
      "source": [
        "tokenized_korean_lines_val = []\n",
        "tokenized_english_lines_val = []\n",
        "\n",
        "for i in range(len(korean_lines_val)):\n",
        "    korean = korean_lines_val[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_val[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    tokenized_korean_lines_val.append(korean_tokens)\n",
        "    tokenized_english_lines_val.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"평가 데이터셋 토큰화: {i + 1}/{len(korean_lines_val)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평가 데이터셋 토큰화: 1000/1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_sP1Wn3pvQU"
      },
      "source": [
        "* 테스트(test) 데이터셋을 토큰화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxY4lieapyQj",
        "outputId": "831d2707-f5ca-4834-8e61-ee00b5c1ff89"
      },
      "source": [
        "tokenized_korean_lines_test = []\n",
        "tokenized_english_lines_test = []\n",
        "\n",
        "for i in range(len(korean_lines_test)):\n",
        "    korean = korean_lines_test[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_test[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    tokenized_korean_lines_test.append(korean_tokens)\n",
        "    tokenized_english_lines_test.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"테스트 데이터셋 토큰화: {i + 1}/{len(korean_lines_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터셋 토큰화: 1000/2000\n",
            "테스트 데이터셋 토큰화: 2000/2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxvJN5THq2hx"
      },
      "source": [
        "#### <b>단어 사전 만들기</b>\n",
        "\n",
        "* 최소 2번 이상 등장한 단어만 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNVKZ7NbrP2l",
        "outputId": "5b40a86d-e98e-42bc-c5b4-a557ba06f6c7"
      },
      "source": [
        "korean_voca = Vocabulary()\n",
        "english_voca = Vocabulary()\n",
        "\n",
        "for i in range(len(tokenized_korean_lines_train)):\n",
        "    korean_tokens = tokenized_korean_lines_train[i]\n",
        "    english_tokens = tokenized_english_lines_train[i]\n",
        "\n",
        "    korean_voca.add_tokens(korean_tokens)\n",
        "    english_voca.add_tokens(english_tokens)\n",
        "\n",
        "korean_voca.preprocess(min_count=2)\n",
        "english_voca.preprocess(min_count=2)\n",
        "\n",
        "print(\"전체 한국어 단어 수:\", len(korean_voca.word2count))\n",
        "print(\"전체 영어 단어 수:\", len(english_voca.word2count))\n",
        "print(\"사용할 한국어 토큰 수:\", len(korean_voca.word2idx))\n",
        "print(\"사용할 영어 토큰 수:\", len(english_voca.word2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 한국어 단어 수: 67029\n",
            "전체 영어 단어 수: 58833\n",
            "사용할 한국어 토큰 수: 40612\n",
            "사용할 영어 토큰 수: 35745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wyKQjwAusyw",
        "outputId": "fc09fe2b-fa8c-43f6-9106-a156b4d389b3"
      },
      "source": [
        "print(korean_voca.word2idx['<pad>']) # 패딩(padding): 1\n",
        "print(korean_voca.word2idx['<sos>']) # <sos>: 2\n",
        "print(korean_voca.word2idx['<eos>']) # <eos>: 3\n",
        "print(korean_voca.word2idx['컴퓨터'])\n",
        "print(korean_voca.word2idx['사랑'])\n",
        "print(korean_voca.word2idx['기적'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "5696\n",
            "27950\n",
            "28975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQjD1bjVuvHt",
        "outputId": "f2a72be3-6a4e-43d3-ed46-cdf163bbf9d6"
      },
      "source": [
        "print(english_voca.word2idx['<pad>']) # 패딩(padding): 1\n",
        "print(english_voca.word2idx['<sos>']) # <sos>: 2\n",
        "print(english_voca.word2idx['<eos>']) # <eos>: 3\n",
        "print(english_voca.word2idx['computer'])\n",
        "print(english_voca.word2idx['love'])\n",
        "print(english_voca.word2idx['miracle'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "10551\n",
            "30840\n",
            "16063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw7jo7dmsHRW"
      },
      "source": [
        "* Unknown Token이 1개 이상 포함된 문장은 데이터셋에서 제외하여 다시 학습 데이터셋을 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M717ROWBsFmM"
      },
      "source": [
        "unknown_threshold = 1\n",
        "\n",
        "preprocessed_korean_lines_train = []\n",
        "preprocessed_english_lines_train = []\n",
        "\n",
        "for i in range(len(tokenized_korean_lines_train)):\n",
        "    korean_tokens = tokenized_korean_lines_train[i]\n",
        "    english_tokens = tokenized_english_lines_train[i]\n",
        "\n",
        "    is_used = True # 현재의 문장 쌍을 사용할지의 여부\n",
        "    for token in korean_tokens:\n",
        "        cnt = 0\n",
        "        if token not in korean_voca.word2idx:\n",
        "            cnt += 1\n",
        "        if cnt >= unknown_threshold:\n",
        "            is_used = False\n",
        "    for token in english_tokens:\n",
        "        cnt = 0\n",
        "        if token not in english_voca.word2idx:\n",
        "            cnt += 1\n",
        "        if cnt >= unknown_threshold:\n",
        "            is_used = False\n",
        "\n",
        "    if not is_used:\n",
        "        continue\n",
        "\n",
        "    preprocessed_korean_lines_train.append(korean_tokens)\n",
        "    preprocessed_english_lines_train.append(english_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg6lc1V4uDQ6",
        "outputId": "ade1074d-09f2-4877-aede-82b141f4340a"
      },
      "source": [
        "print(\"사용할 한국어 학습 문장 수:\", len(preprocessed_korean_lines_train))\n",
        "print(\"사용할 영어 학습 문장 수:\", len(preprocessed_english_lines_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용할 한국어 학습 문장 수: 61029\n",
            "사용할 영어 학습 문장 수: 61029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH1SIu_i5mch",
        "outputId": "5948f475-afd2-4601-bb6f-67e55b75d52d"
      },
      "source": [
        "print(preprocessed_korean_lines_train[7777])\n",
        "print(preprocessed_english_lines_train[7777])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cnn', '의', '여론조사', '국장', '인', '키팅', '홀랜드', '는', '“', '이라크전', '발발', '직후', '부시', '의', '지지도', '는', '71', '였다', '”', '며', '“', '지지율', '40', '추락', '은', '베트남전', '당시', '린', '든', '존슨', '대통령', '과', '유사하다', '”', '고', '지적', '했다']\n",
            "['bushs', 'approval', 'rating', 'five', 'years', 'ago', 'at', 'the', 'start', 'of', 'the', 'iraq', 'war', 'was', '71', 'percent', 'and', 'that', '40point', 'drop', 'is', 'almost', 'identical', 'to', 'the', 'drop', 'president', 'lyndon', 'johnson', 'faced', 'during', 'the', 'vietnam', 'war', 'said', 'cnn', 'polling', 'director', 'keating', 'holland']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eItQjid_uzsB"
      },
      "source": [
        "#### <b>커스텀 데이터셋 클래스 작성하기</b>\n",
        "\n",
        "* 소스 문장(한국어)과 타겟 문장(영어)를 한 쌍으로 반환하는 데이터셋 클래스를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C7JV5PE5rmM"
      },
      "source": [
        "import copy\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, korean_lines, english_lines, max_seq_len):\n",
        "        self.korean_lines = korean_lines\n",
        "        self.english_lines = english_lines\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoder_input = self.get_encoder_input(self.korean_lines[index])\n",
        "        decoder_input = self.get_decoder_input(self.english_lines[index])\n",
        "\n",
        "        return encoder_input, decoder_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.korean_lines)\n",
        "\n",
        "    # 한글 문장 벡터화\n",
        "    def get_encoder_input(self, tokens):\n",
        "        tokens = copy.deepcopy(tokens)\n",
        "        tokens.insert(0, korean_voca.SOS)\n",
        "        tokens.append(korean_voca.EOS)\n",
        "        tokens = self.padding(tokens, korean_voca) # 문장 뒤쪽에 패딩 붙이기\n",
        "        index_list = self.word2idx(tokens, korean_voca)\n",
        "\n",
        "        return torch.tensor(index_list).to(device)\n",
        "\n",
        "    # 영어 문장 벡터화\n",
        "    def get_decoder_input(self, tokens):\n",
        "        tokens = copy.deepcopy(tokens)\n",
        "        tokens.insert(0, english_voca.SOS)\n",
        "        tokens.append(english_voca.EOS)\n",
        "        tokens = self.padding(tokens, english_voca) # 문장 뒤쪽에 패딩 붙이기\n",
        "        index_list = self.word2idx(tokens, english_voca)\n",
        "\n",
        "        return torch.tensor(index_list).to(device)\n",
        "\n",
        "    # max_seq_len보다 길이가 짧은 문장에 대해 <pad> 토큰 채우기\n",
        "    def padding(self, tokens, voca):\n",
        "        if len(tokens) < self.max_seq_len:\n",
        "            tokens += [voca.PAD] * (self.max_seq_len - len(tokens))\n",
        "        else:\n",
        "            tokens = tokens[:self.max_seq_len]\n",
        "        return tokens\n",
        "\n",
        "    def word2idx(self, tokens, voca):\n",
        "        idx_list = []\n",
        "        for token in tokens:\n",
        "            try:\n",
        "                idx_list.append(voca.word2idx[token])\n",
        "            except KeyError:\n",
        "                idx_list.append(voca.word2idx[voca.UNK])\n",
        "        return idx_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EObNRkSSvPfk"
      },
      "source": [
        "* 학습/평가/테스트 데이터셋 객체를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBsC-CRc5_F7"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = CustomDataset(preprocessed_korean_lines_train, preprocessed_english_lines_train, max_seq_len=80)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=128, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(tokenized_korean_lines_val, tokenized_english_lines_val, max_seq_len=80)\n",
        "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=128, num_workers=0)\n",
        "\n",
        "test_dataset = CustomDataset(tokenized_korean_lines_test, tokenized_english_lines_test, max_seq_len=80)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=128, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlKQSsxK6BdK",
        "outputId": "b9d4acec-6245-4a95-f36e-7afa474dc9c9"
      },
      "source": [
        "# 하나의 배치에 포함되어 있는 문장을 출력합니다.\n",
        "for i, batch in enumerate(train_loader):\n",
        "    src = batch[0]\n",
        "    trg = batch[1]\n",
        "\n",
        "    print(f\"첫 번째 배치 크기: {src.shape}\")\n",
        "\n",
        "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "    for i in range(src.shape[1]):\n",
        "        print(f\"인덱스 {i}: {src[0][i].item()}\") # 여기에서는 [Seq_num, Seq_len]\n",
        "\n",
        "    # 첫 번째 배치만 확인\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 배치 크기: torch.Size([128, 80])\n",
            "인덱스 0: 2\n",
            "인덱스 1: 9527\n",
            "인덱스 2: 20597\n",
            "인덱스 3: 38910\n",
            "인덱스 4: 3052\n",
            "인덱스 5: 25705\n",
            "인덱스 6: 40269\n",
            "인덱스 7: 37514\n",
            "인덱스 8: 26887\n",
            "인덱스 9: 3\n",
            "인덱스 10: 1\n",
            "인덱스 11: 1\n",
            "인덱스 12: 1\n",
            "인덱스 13: 1\n",
            "인덱스 14: 1\n",
            "인덱스 15: 1\n",
            "인덱스 16: 1\n",
            "인덱스 17: 1\n",
            "인덱스 18: 1\n",
            "인덱스 19: 1\n",
            "인덱스 20: 1\n",
            "인덱스 21: 1\n",
            "인덱스 22: 1\n",
            "인덱스 23: 1\n",
            "인덱스 24: 1\n",
            "인덱스 25: 1\n",
            "인덱스 26: 1\n",
            "인덱스 27: 1\n",
            "인덱스 28: 1\n",
            "인덱스 29: 1\n",
            "인덱스 30: 1\n",
            "인덱스 31: 1\n",
            "인덱스 32: 1\n",
            "인덱스 33: 1\n",
            "인덱스 34: 1\n",
            "인덱스 35: 1\n",
            "인덱스 36: 1\n",
            "인덱스 37: 1\n",
            "인덱스 38: 1\n",
            "인덱스 39: 1\n",
            "인덱스 40: 1\n",
            "인덱스 41: 1\n",
            "인덱스 42: 1\n",
            "인덱스 43: 1\n",
            "인덱스 44: 1\n",
            "인덱스 45: 1\n",
            "인덱스 46: 1\n",
            "인덱스 47: 1\n",
            "인덱스 48: 1\n",
            "인덱스 49: 1\n",
            "인덱스 50: 1\n",
            "인덱스 51: 1\n",
            "인덱스 52: 1\n",
            "인덱스 53: 1\n",
            "인덱스 54: 1\n",
            "인덱스 55: 1\n",
            "인덱스 56: 1\n",
            "인덱스 57: 1\n",
            "인덱스 58: 1\n",
            "인덱스 59: 1\n",
            "인덱스 60: 1\n",
            "인덱스 61: 1\n",
            "인덱스 62: 1\n",
            "인덱스 63: 1\n",
            "인덱스 64: 1\n",
            "인덱스 65: 1\n",
            "인덱스 66: 1\n",
            "인덱스 67: 1\n",
            "인덱스 68: 1\n",
            "인덱스 69: 1\n",
            "인덱스 70: 1\n",
            "인덱스 71: 1\n",
            "인덱스 72: 1\n",
            "인덱스 73: 1\n",
            "인덱스 74: 1\n",
            "인덱스 75: 1\n",
            "인덱스 76: 1\n",
            "인덱스 77: 1\n",
            "인덱스 78: 1\n",
            "인덱스 79: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bieO3YwVvmLY"
      },
      "source": [
        "#### **Multi Head Attention 아키텍처**\n",
        "\n",
        "* 어텐션(attention)은 <b>세 가지 요소</b>를 입력으로 받습니다.\n",
        "    * <b>쿼리(queries)</b>\n",
        "    * <b>키(keys)</b>\n",
        "    * <b>값(values)</b>\n",
        "    * 현재 구현에서는 Query, Key, Value의 차원이 모두 같습니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRX0AoF1voKW"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
        "        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
        "        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
        "\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # query: [batch_size, query_len, hidden_dim]\n",
        "        # key: [batch_size, key_len, hidden_dim]\n",
        "        # value: [batch_size, value_len, hidden_dim]\n",
        " \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        # Q: [batch_size, query_len, hidden_dim]\n",
        "        # K: [batch_size, key_len, hidden_dim]\n",
        "        # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
        "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "        # K: [batch_size, n_heads, key_len, head_dim]\n",
        "        # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "        # Attention Energy 계산\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 마스크(mask)를 사용하는 경우\n",
        "        if mask is not None:\n",
        "            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n",
        "            energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 여기에서 Scaled Dot-Product Attention을 계산\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # x: [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        return x, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzSDUlmOvq6-"
      },
      "source": [
        "#### **Position-wise Feedforward 아키텍처**\n",
        "\n",
        "* 입력과 출력의 차원이 동일합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBfNsiED6LSe"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6fWXndvvwJ"
      },
      "source": [
        "#### **인코더(Encoder) 레이어 아키텍처**\n",
        "\n",
        "* 하나의 인코더 레이어에 대해 정의합니다.\n",
        "    * 입력과 출력의 차원이 같습니다.\n",
        "    * 이러한 특징을 이용해 트랜스포머의 인코더는 인코더 레이어를 여러 번 중첩해 사용합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwhr1-df6MKk"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N22uqlEmvx06"
      },
      "source": [
        "#### **인코더(Encoder) 아키텍처**\n",
        "\n",
        "* 전체 인코더 아키텍처를 정의합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **input_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "    * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 <b>위치 임베딩(positional embedding)을 학습</b>하는 형태로 구현합니다.\n",
        "    * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "* &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j2ZRWaf6M14"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, src_len]\n",
        "\n",
        "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src # 마지막 레이어의 출력을 반환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl-eh0mAvzva"
      },
      "source": [
        "#### **디코더(Decoder) 레이어 아키텍처**\n",
        "\n",
        "* 하나의 디코더 레이어에 대해 정의합니다.\n",
        "    * 입력과 출력의 차원이 같습니다.\n",
        "    * 이러한 특징을 이용해 트랜스포머의 디코더는 디코더 레이어를 여러 번 중첩해 사용합니다.\n",
        "    * 디코더 레이어에서는 두 개의 Multi-Head Attention 레이어가 사용됩니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* 소스 문장의 &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBalCQMq6Nj4"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 자기 자신에 대하여 어텐션(attention)\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # encoder attention\n",
        "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return trg, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kRYUk-1v1jv"
      },
      "source": [
        "#### **디코더(Decoder) 아키텍처**\n",
        "\n",
        "* 전체 디코더 아키텍처를 정의합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **output_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "    * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 <b>위치 임베딩(positional embedding)을 학습</b>하는 형태로 구현합니다.\n",
        "    * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "* Seq2Seq과는 마찬가지로 실제로 추론(inference) 시기에서는 디코더를 반복적으로 넣을 필요가 있습니다.\n",
        "    * 학습(training) 시기에서는 한 번에 출력 문장을 구해 학습할 수 있습니다.\n",
        "* 소스 문장의 &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzJ-DCDt6Oev"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn-yCx4yv348"
      },
      "source": [
        "#### **트랜스포머(Transformer) 아키텍처**\n",
        "\n",
        "* 최종적인 전체 트랜스포머(Transformer) 모델을 정의합니다.\n",
        "* 입력이 들어왔을 때 앞서 정의한 인코더와 디코더를 거쳐 출력 문장을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ignEkCL6PSr"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        \"\"\"\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 1 0\n",
        "        1 1 1 1 1\n",
        "        \"\"\"\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1TDOflzv5xW"
      },
      "source": [
        "#### **학습(Training)**\n",
        "\n",
        "* 하이퍼 파라미터 설정 및 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ombHNgO56Q7r"
      },
      "source": [
        "INPUT_DIM = len(korean_voca.word2idx)\n",
        "OUTPUT_DIM = len(english_voca.word2idx)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W-Tr-D06SbJ"
      },
      "source": [
        "SRC_PAD_IDX = korean_voca.word2idx[korean_voca.PAD]\n",
        "TRG_PAD_IDX = english_voca.word2idx[english_voca.PAD]\n",
        "\n",
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1DbVBkVwCvA"
      },
      "source": [
        "* **모델 가중치 파라미터 초기화**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XObg1hxB6bOA",
        "outputId": "278215bb-3c1d-4a51-f617-14e24be007a6"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 32,738,721 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWItEfu26chy",
        "outputId": "14a64926-3f70-421b-a633-b0c12f2d0974"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(40612, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(35745, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=35745, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Je4gMnSwITT"
      },
      "source": [
        "* 학습 및 평가 함수 정의\n",
        "    * 기본적인 Seq2Seq 모델과 거의 유사하게 작성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_hn64HD6dYK"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg6MC3dK6gF9"
      },
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch[0]\n",
        "        trg = batch[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "        # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "\n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEukz7xc6o6F"
      },
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[0]\n",
        "            trg = batch[1]\n",
        "\n",
        "            # 출력 단어의 마지막 인덱스(<eos>)는 제외\n",
        "            # 입력을 할 때는 <sos>부터 시작하도록 처리\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            # output: [배치 크기, trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기, trg_len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            # 출력 단어의 인덱스 0(<sos>)은 제외\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4-D3IuNwO9t"
      },
      "source": [
        "* 학습(training) 및 검증(validation) 진행\n",
        "    * **학습 횟수(epoch)**: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuAulfy_6pow"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC-dgh1E6qbF",
        "outputId": "657ba879-47f7-411a-8d49-1b3e8d685025"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "N_EPOCHS = 4\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'transformer_korean_to_english.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 2m 47s\n",
            "\tTrain Loss: 6.359 | Train PPL: 577.873\n",
            "\tValidation Loss: 5.954 | Validation PPL: 385.099\n",
            "Epoch: 02 | Time: 2m 48s\n",
            "\tTrain Loss: 5.039 | Train PPL: 154.348\n",
            "\tValidation Loss: 5.620 | Validation PPL: 276.015\n",
            "Epoch: 03 | Time: 2m 48s\n",
            "\tTrain Loss: 4.333 | Train PPL: 76.150\n",
            "\tValidation Loss: 5.526 | Validation PPL: 251.169\n",
            "Epoch: 04 | Time: 2m 48s\n",
            "\tTrain Loss: 3.750 | Train PPL: 42.519\n",
            "\tValidation Loss: 5.545 | Validation PPL: 255.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw1ntWEV6uth"
      },
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(korean, model, device, max_len=80, logging=True):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    korean = clean_string(korean)\n",
        "    tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    # 처음에 <sos> 토큰, 마지막에 <eos> 토큰 붙이기\n",
        "    tokens = [korean_voca.SOS] + tokens + [korean_voca.EOS]\n",
        "    if logging:\n",
        "        print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = []\n",
        "    for token in tokens:\n",
        "        try:\n",
        "            src_indexes.append(korean_voca.word2idx[token])\n",
        "        except KeyError:\n",
        "            src_indexes.append(korean_voca.word2idx[korean_voca.UNK])\n",
        "    if logging:\n",
        "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # 소스 문장에 따른 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 처음에는 <sos> 토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [english_voca.word2idx[english_voca.SOS]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        # 출력 문장에 따른 마스크 생성\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 출력 문장에서 가장 마지막 단어만 사용\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # <eos>를 만나는 순간 끝\n",
        "        if pred_token == english_voca.word2idx[english_voca.EOS]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [english_voca.idx2word[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째 <sos>는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avx76dMr9mXm",
        "outputId": "e6fa9a0f-3087-4e59-8a22-fced3a733fef"
      },
      "source": [
        "example_idx = 15\n",
        "\n",
        "src = korean_lines_test[example_idx]\n",
        "trg = english_lines_test[example_idx]\n",
        "\n",
        "print(f'소스 문장: {src}', end='')\n",
        "print(f'타겟 문장: {trg}', end='')\n",
        "\n",
        "translation, attention = translate_sentence(src, model, device, logging=True)\n",
        "\n",
        "print(\"모델 출력 결과:\", \" \".join(translation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소스 문장: 도쿄의 니케이 지수는 9291.03으로 0.33 퍼센트 하락했다.\n",
            "타겟 문장: Tokyo's Nikkei is off 0.33 percent to 9291.03.\n",
            "전체 소스 토큰: ['<sos>', '도쿄', '의', '니', '케이', '지수', '는', '929103', '으로', '033', '퍼센트', '하락', '했다', '<eos>']\n",
            "소스 문장 인덱스: [2, 2362, 22801, 37908, 20455, 15818, 33106, 0, 32511, 0, 14967, 34532, 10688, 3]\n",
            "모델 출력 결과: tokyo is now down a gallon <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2360KqGAcHNX"
      },
      "source": [
        "* 어텐션 맵(Attention Map) 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEhp1bcE33uU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention, n_heads=8, n_rows=4, n_cols=2):\n",
        "\n",
        "    assert n_rows * n_cols == n_heads\n",
        "\n",
        "    plt.rc('font', family='NanumBarunGothic') # 폰트 설정\n",
        "    fig = plt.figure(figsize=(15, 25)) # 출력할 그림 크기 조절\n",
        "\n",
        "    for i in range(n_heads):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i + 1)\n",
        "\n",
        "        # 어텐션(Attention) 스코어 확률 값을 이용해 그리기\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>'], rotation=45)\n",
        "        ax.set_yticklabels([''] + translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzlH8RZEcIJF",
        "outputId": "37dcaadf-a457-4000-dbbd-68a9fbac3b2c"
      },
      "source": [
        "src = \"남한과 미국은 동맹적인 관계를 유지하고 있다.\"\n",
        "\n",
        "print(f'소스 문장: {src}')\n",
        "\n",
        "translation, attention = translate_sentence(src, model, device, logging=True)\n",
        "\n",
        "print(\"모델 출력 결과:\", \" \".join(translation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소스 문장: 남한과 미국은 동맹적인 관계를 유지하고 있다.\n",
            "전체 소스 토큰: ['<sos>', '남한', '과', '미국', '은', '동맹', '적', '인', '관계', '를', '유지', '하고', '있다', '<eos>']\n",
            "소스 문장 인덱스: [2, 3570, 30451, 9038, 39864, 1318, 33706, 4351, 3371, 20852, 4228, 38703, 7367, 3]\n",
            "모델 출력 결과: south korea and the united states are now working with the united states <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dnwiCsNlcKkU",
        "outputId": "9ad6e0d4-83bc-48c9-d602-39e08a74f76c"
      },
      "source": [
        "src = clean_string(src)\n",
        "korean_tokens = [line[0] for line in okt.pos(src, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "display_attention(korean_tokens, translation, attention)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45224 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54620 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44284 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48120 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44397 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51008 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46041 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47609 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51201 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51064 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44288 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44228 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47484 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54616 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51080 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45224 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54620 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44284 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48120 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44397 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51008 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46041 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47609 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51201 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51064 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44288 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44228 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47484 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50976 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54616 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51080 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1800 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdEp459kf2Bz"
      },
      "source": [
        "#### <b>BLEU Score 계산</b>\n",
        "\n",
        "* 학습된 트랜스포머(Transformer) 모델의 BLEU 스코어 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76pGgi0IcS6M"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def show_bleu(model, device, max_len=80):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "    index = 0\n",
        "\n",
        "    for i in range(len(korean_lines_test)):\n",
        "        src = korean_lines_test[i]\n",
        "        trg = english_lines_test[i]\n",
        "\n",
        "        trg = clean_string(trg)\n",
        "        trg = trg.split(' ')\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, model, device, max_len, logging=False)\n",
        "\n",
        "        # 마지막 <eos> 토큰 제거\n",
        "        pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "\n",
        "        index += 1\n",
        "        if (index + 1) % 100 == 0:\n",
        "            print(f\"[{index + 1}/{len(korean_lines_test)}]\")\n",
        "            print(f\"예측: {pred_trg}\")\n",
        "            print(f\"정답: {trg}\")\n",
        "\n",
        "    bleu = bleu_score(pred_trgs, trgs, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
        "    print(f'Total BLEU Score = {bleu*100:.2f}')\n",
        "\n",
        "    individual_bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
        "    individual_bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 1, 0, 0])\n",
        "    individual_bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 1, 0])\n",
        "    individual_bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[0, 0, 0, 1])\n",
        "\n",
        "    print(f'Individual BLEU1 score = {individual_bleu1_score*100:.2f}') \n",
        "    print(f'Individual BLEU2 score = {individual_bleu2_score*100:.2f}') \n",
        "    print(f'Individual BLEU3 score = {individual_bleu3_score*100:.2f}') \n",
        "    print(f'Individual BLEU4 score = {individual_bleu4_score*100:.2f}') \n",
        "\n",
        "    cumulative_bleu1_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1, 0, 0, 0])\n",
        "    cumulative_bleu2_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/2, 1/2, 0, 0])\n",
        "    cumulative_bleu3_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/3, 1/3, 1/3, 0])\n",
        "    cumulative_bleu4_score = bleu_score(pred_trgs, trgs, max_n=4, weights=[1/4, 1/4, 1/4, 1/4])\n",
        "\n",
        "    print(f'Cumulative BLEU1 score = {cumulative_bleu1_score*100:.2f}') \n",
        "    print(f'Cumulative BLEU2 score = {cumulative_bleu2_score*100:.2f}') \n",
        "    print(f'Cumulative BLEU3 score = {cumulative_bleu3_score*100:.2f}') \n",
        "    print(f'Cumulative BLEU4 score = {cumulative_bleu4_score*100:.2f}') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuh4aVgCf3MU",
        "outputId": "04cc545f-6c9d-445d-9b8c-cb42abebc584"
      },
      "source": [
        "show_bleu(model, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100/2000]\n",
            "예측: ['the', 'french', 'newspaper', 'found', 'that', 'the', 'dna', 'of', 'the', 'dna', 'testing', 'a', 'german', 'journalist', 'who', 'was', 'found', 'guilty', 'of', 'a', 'russian', 'vessel', 'in', 'the', 'western', 'province', 'of', 'rape']\n",
            "정답: ['the', 'skull', 'nicknamed', 'toumai', 'found', 'in', 'northern', 'chad', 'by', 'an', 'international', 'team', 'is', 'not', 'part', 'of', 'the', 'human', 'family', 'tree']\n",
            "[200/2000]\n",
            "예측: ['the', 'boy', 'was', 'found', 'unconscious', 'and', 'in', 'the', 'weekend', 'when', 'he', 'was', 'found', 'dead', 'and', 'a', 'man', 'who', 'died', 'in', 'a', 'hospital']\n",
            "정답: ['johnsons', 'eviscerated', 'body', 'which', 'police', 'said', 'they', 'found', 'after', 'receiving', 'calls', 'about', 'a', 'foul', 'odor', 'coming', 'from', 'the', 'apartment', 'was', 'in', 'a', 'state', 'of', 'moderate', 'decomposition', 'and', 'she', 'had', 'been', 'dead', 'about', 'two', 'days', 'medical', 'examiner', 'karl', 'williams', 'said']\n",
            "[300/2000]\n",
            "예측: ['the', 'study', 'was', 'found', 'in', 'the', 'past', 'five', 'years', 'of', 'results', 'were', 'found', 'in', 'the', 'report']\n",
            "정답: ['studies', 'show', 'productivity', 'drops', 'when', 'temperatures', 'dip', 'below', '72', 'degrees']\n",
            "[400/2000]\n",
            "예측: ['he', 'said', 'he', 'had', 'been', 'charged', 'with', 'attempted', 'murder', 'charges', 'against', 'corruption', 'and', 'conspiracy', 'to', 'pay', 'a', 'million', 'for', 'a', 'fine']\n",
            "정답: ['the', 'couple', 'who', 'face', 'charges', 'of', 'bodily', 'harm', 'making', 'threats', 'and', 'coercion', 'were', 'released', 'on', 'bail', 'thursday', 'he', 'said']\n",
            "[500/2000]\n",
            "예측: ['the', 'israeli', 'army', 'said', 'the', 'blast', 'was', 'killed', 'in', 'the', 'area', 'of', 'the', 'attack']\n",
            "정답: ['israel', 'on', 'wednesday', 'also', 'released', 'the', 'remains', 'of', '199', 'fighters', 'from', 'lebanon']\n",
            "[600/2000]\n",
            "예측: ['the', 'us', 'geological', 'survey', 'said', 'the', 'island', 'of', 'diyarbakir', 'killed', 'a', 'us', 'geological', 'survey', 'of', 'the', 'island']\n",
            "정답: ['a', 'strong', 'earthquake', 'struck', 'monday', 'near', 'some', 'greek', 'islands', 'close', 'to', 'the', 'turkish', 'coast', 'according', 'to', 'the', 'us', 'geological', 'service']\n",
            "[700/2000]\n",
            "예측: ['the', 'last', 'month', 'was', 'released', 'after', 'the', 'june', '5', 'but', 'was', 'not', 'allowed', 'to', 'take', 'a', 'row', 'over', 'the', 'past', 'few', 'days']\n",
            "정답: ['inbevs', 'original', 'offer', 'of', '46', 'billion', 'made', 'on', 'june', '11th', 'was', 'rejected', 'as', 'too', 'low']\n",
            "[800/2000]\n",
            "예측: ['but', 'in', 'a', 'small', 'river', 'in', 'tokyo', 'that', 'she', 'said', 'she', 'had', 'been', 'able', 'to', 'be', 'able', 'to', 'be', 'able', 'to', 'avoid', 'a', 'small', 'fraction', 'of', 'the', 'water', 'or', 'other', 'species']\n",
            "정답: ['but', 'she', 'points', 'out', 'that', 'the', 'jewelry', 'is', 'almost', 'always', 'made', 'from', 'cheap', 'metal', 'that', 'will', 'turn', 'yellow', 'or', 'lose', 'its', 'sheen', 'within', 'weeks']\n",
            "[900/2000]\n",
            "예측: ['iran', 'has', 'been', 'a', 'us', 'official', 'said', 'on', 'iran', 'was', 'a', 'nuclear', 'bomb', 'in', 'the', 'past', 'two', 'weeks']\n",
            "정답: ['iranian', 'media', 'reported', 'that', 'tehran', 'fired', 'a', 'series', 'of', 'missiles', 'on', 'thursday', 'in', 'a', 'second', 'day', 'of', 'longrange', 'missile', 'testing']\n",
            "[1000/2000]\n",
            "예측: ['the', 'man', 'who', 'was', 'killed', 'in', 'a', 'village', 'of', 'baquba', 'police', 'said', 'he', 'was', 'a', 'woman', 'who', 'was', 'killed', 'and', 'wounded', 'when', 'he', 'was', 'killed', 'by', 'a', 'spokesman', 'for', 'the', 'interior', 'ministry', 'said']\n",
            "정답: ['when', 'police', 'surrounded', 'the', 'men¡¯s', 'apartment', 'tuesday', 'they', 'found', '15', 'men', 'and', 'women', 'wielding', 'knives', 'and', 'shouting', '¡°sacrifice', 'for', 'allah¡±', 'a', 'police', 'spokesman', 'told', 'xinhua']\n",
            "[1100/2000]\n",
            "예측: ['north', 'korea', 'has', 'been', 'criticized', 'for', 'a', 'series', 'of', 'nuclear', 'program', 'since', 'september']\n",
            "정답: ['north', 'korea', 'declared', 'details', 'of', 'its', 'nuclear', 'program', 'last', 'month']\n",
            "[1200/2000]\n",
            "예측: ['president', 'george', 'w', 'bush', 'said', 'the', 'us', 'president', 'has', 'a', 'positive', 'impact', 'on', 'the', 'global', 'financial', 'crisis']\n",
            "정답: ['president', 'bush', 'gave', 'a', 'positive', 'but', 'cautious', 'assessment', 'of', 'russia¡¯s', 'new', 'president', 'dmitry', 'medvedev']\n",
            "[1300/2000]\n",
            "예측: ['but', 'the', 'other', 'countries', 'are', 'also', 'known', 'as', 'the', 'worlds', 'most', 'famous', 'colors', 'of', 'the', 'world', 'cup', 'winners', 'in', 'the', 'world', 'cup']\n",
            "정답: ['von', 'hagens', 'says', 'he', 'relies', 'on', 'donors', 'not', 'only', 'as', 'a', 'source', 'of', 'specimens', 'but', 'also', 'as', 'representations', 'of', 'body', 'worlds', 'philosophy']\n",
            "[1400/2000]\n",
            "예측: ['ma', 'yingjeou', 'has', 'been', 'cultivating', 'ties', 'with', 'the', 'chinese', 'leader', 'of', 'the', 'dalai', 'lama']\n",
            "정답: ['taiwans', 'new', 'president', 'ma', 'yingjeou', 'has', 'rejected', 'the', 'push', 'for', 'independence']\n",
            "[1500/2000]\n",
            "예측: ['walter', 'hill', 'won', 'the', 'new', 'study', 'the', 'new', 'york', 'times', 'in', 'the', 'world', 'the', 'new', 'york', 'times', 'said', 'the', 'company', 'had', 'a', 'bid', 'to', 'sell', 'the', 'money']\n",
            "정답: ['walter', 'scott', '24', 'put', 'his', 'soul', 'up', 'for', 'sale', 'on', 'new', 'zealand', 'internet', 'auction', 'site', 'trademe', 'and', 'so', 'far', 'has', 'received', 'more', 'than', '100', 'expressions', 'of', 'interest']\n",
            "[1600/2000]\n",
            "예측: ['north', 'korea', 'has', 'been', 'trying', 'to', 'resolve', 'the', 'crisis', 'over', 'the', 'norths', 'nuclear', 'program']\n",
            "정답: ['but', 'the', 'governing', 'uri', 'party', 'still', 'underlined', 'the', 'importance', 'of', 'interkorean', 'economic', 'projects']\n",
            "[1700/2000]\n",
            "예측: ['the', 'gunman', 'killed', 'at', 'least', 'eight', 'people', 'in', 'the', 'area', 'where', 'he', 'was', 'killed', 'and', 'a', 'marine', 'in', 'the', 'area', 'where', 'he', 'said']\n",
            "정답: ['regional', 'officials', 'said', 'he', 'died', 'in', 'a', 'shootout', 'when', 'marines', 'swooped', 'on', 'his', 'hideout', 'in', 'the', 'island', 'of', 'tawitawi']\n",
            "[1800/2000]\n",
            "예측: ['the', 'united', 'states', 'has', 'been', 'pushing', 'for', 'a', 'resolution', 'to', 'the', 'un', 'secretarygeneral']\n",
            "정답: ['the', 'move', 'was', 'opposed', 'by', 'the', 'party', 'of', 'president', 'nicolas', 'sarkozy', 'who', 'has', 'been', 'trying', 'to', 'ease', 'tense', 'ties', 'with', 'beijing']\n",
            "[1900/2000]\n",
            "예측: ['the', 'dow', 'is', 'up', 'about', '10', 'points']\n",
            "정답: ['right', 'now', 'the', 'dow', 'is', 'up', '14', 'points']\n",
            "[2000/2000]\n",
            "예측: ['japan', 'is', 'a', 'powerful', 'earthquake', 'to', 'have', 'killed', 'at', 'least', '10', 'people']\n",
            "정답: ['japans', 'derailed', 'commuter', 'train', 'accident', 'has', 'killed', 'at', 'least', '69', 'people']\n",
            "Total BLEU Score = 1.88\n",
            "Individual BLEU1 score = 20.93\n",
            "Individual BLEU2 score = 3.44\n",
            "Individual BLEU3 score = 0.80\n",
            "Individual BLEU4 score = 0.22\n",
            "Cumulative BLEU1 score = 20.93\n",
            "Cumulative BLEU2 score = 8.48\n",
            "Cumulative BLEU3 score = 3.86\n",
            "Cumulative BLEU4 score = 1.88\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}